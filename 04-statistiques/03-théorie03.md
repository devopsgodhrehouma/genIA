# Distribution des Donn√©es üé≤

La **distribution des donn√©es** d√©crit la mani√®re dont les valeurs sont r√©parties.

1. **Distribution normale (ou en cloche)** :
   - C'est une forme de distribution o√π la plupart des valeurs se concentrent autour de la moyenne.
   - Elle ressemble √† une courbe en forme de cloche : la moyenne, la m√©diane et le mode sont au m√™me endroit, au centre.
   - Exemples : Taille et poids de personnes dans une population.

2. **Distribution asym√©trique** :
   - **Asym√©trie √† droite** : La queue de la courbe est plus longue vers la droite. Exemple : Revenus, o√π la majorit√© gagne peu, mais quelques personnes gagnent beaucoup.
   - **Asym√©trie √† gauche** : La queue est plus longue vers la gauche.

### Les Corr√©lations üîó

La **corr√©lation** mesure le lien entre deux variables (par exemple, la taille et le poids). Elle aide √† savoir si, lorsqu'une variable augmente, l‚Äôautre a tendance √† augmenter, diminuer ou rester la m√™me.

1. **Types de corr√©lation** :
   - **Corr√©lation positive** : Les deux variables augmentent ensemble (ex. : la taille et le poids).
   - **Corr√©lation n√©gative** : Une variable augmente tandis que l'autre diminue (ex. : le nombre d'heures de sommeil et le stress).
   - **Corr√©lation nulle** : Aucun lien (ex. : la taille d'une personne et ses notes √† l'√©cole).

2. **Coefficient de corr√©lation (r)** :
   - Va de -1 (corr√©lation n√©gative parfaite) √† +1 (corr√©lation positive parfaite).
   - Une corr√©lation proche de 0 signifie qu‚Äôil n‚Äôy a pas de lien entre les variables.

### Tests de Significativit√© üìè

Les tests de significativit√© permettent de v√©rifier si les r√©sultats observ√©s sont dus au hasard ou s'ils sont significatifs.

1. **Hypoth√®ses** :
   - **Hypoth√®se nulle (H0)** : Suppose qu'il n‚Äôy a aucun effet ou diff√©rence (ex. : aucune diff√©rence entre deux groupes).
   - **Hypoth√®se alternative (H1)** : Suppose qu'il y a un effet ou une diff√©rence.

2. **p-valeur** :
   - Si **p < 0.05**, le r√©sultat est souvent consid√©r√© comme "significatif". Cela signifie qu'il y a moins de 5 % de chances que le r√©sultat soit d√ª au hasard.
   - Ex : Si on compare les notes d‚Äôun groupe d‚Äô√©l√®ves ayant eu du tutorat avec un groupe sans tutorat, une p-valeur faible indiquerait que le tutorat a probablement eu un impact.

### Intervalle de Confiance üéØ

Un **intervalle de confiance** est une plage de valeurs qui a de fortes chances de contenir la valeur vraie de la population.

1. **Exemple** :
   - Si on dit qu'un sondage indique que 60 % des personnes aiment le chocolat avec un intervalle de confiance de 95 %, cela signifie que si l‚Äôon refait le sondage plusieurs fois, 95 % du temps, la vraie valeur sera proche de 60 %.
  
### R√©gression Lin√©aire üìà

La **r√©gression lin√©aire** aide √† pr√©dire une variable en fonction d'une autre. Elle est repr√©sent√©e par une droite (ou "ligne de tendance") sur un graphique.

1. **Exemple** :
   - Si on veut pr√©dire le score d'un √©tudiant en fonction de ses heures d‚Äô√©tude, on peut utiliser la r√©gression lin√©aire pour obtenir une √©quation : `Score = 5 + 3 * Heures d'√©tude`.

2. **Interpr√©tation** :
   - **Coefficient** : Dans l‚Äô√©quation `Score = 5 + 3 * Heures`, le coefficient 3 signifie que chaque heure d'√©tude suppl√©mentaire augmente le score de 3 points.
   - **Intercept (5)** : C‚Äôest le score de base (ici, 5) sans aucune heure d‚Äô√©tude.

### √âchantillonnage üìã

L‚Äô**√©chantillonnage** consiste √† s√©lectionner une partie de la population pour en tirer des conclusions.

1. **Types d'√©chantillons** :
   - **Al√©atoire** : Chaque individu a la m√™me chance d'√™tre choisi.
   - **Stratifi√©** : La population est divis√©e en groupes, et un √©chantillon est pris dans chaque groupe.

2. **Biais de l'√©chantillonnage** :
   - Un √©chantillon biais√© peut donner des r√©sultats non repr√©sentatifs. Par exemple, sonder uniquement des lyc√©ens pour un avis g√©n√©ral sur le travail pourrait donner un r√©sultat non repr√©sentatif de toute la population.

